first_allna_row <- which(
diff(c(rowSums(is.na(df)) != ncol(df), 0)) != 0)[1]
dplyr::slice_head(df, n = first_allna_row)
})() |>
dplyr::mutate(
## convert sample column to unique numeric values in seconds
## https://github.com/fmmattioni/whippr/blob/master/R/read-data.R
## detects either character or dttm formats
## tested on Moxy, PerfPro, Oxysoft, VMPro x2
## TODO test on Train.Red, NNOXX, Graspor, Oxysoft csv, ...
dplyr::across(
dplyr::any_of(names(sample_column)) &
dplyr::where(is.character),
\(.x) as.POSIXct(.x, tryFormats = c(
"%Y-%m-%d %H:%M:%OS", "%Y/%m/%d %H:%M:%OS", "%H:%M:%OS"),
format = "%H:%M:%OS")),
## adds a sequential index column
dplyr::across(
dplyr::any_of(names(nirs_columns[1])),
\(.x) seq_along(.x),
.names = "index"),
) |>
dplyr::relocate(index)
## Soft check sample values if sample_column is present
if (!is.null(names(sample_column))) {
sample_vector <- as.numeric(raw_data_prepared[[names(sample_column)]])
## validation: soft check whether sample_column has non-sequential or
## repeating values
if (any(c(diff(sample_vector) <= 0, FALSE) | duplicated(sample_vector))) {
repeated_samples <- raw_data_prepared |>
dplyr::filter(
c(diff(get(names(sample_column))) <= 0, FALSE) |
duplicated(get(names(sample_column)))
) |>
dplyr::pull(index)
cli::cli_warn(paste(
"{.arg sample_column} = {.val {names(sample_column)}} has",
"non-sequential or repeating values. Consider investigating at",
if (length(repeated_samples) > 5) {
paste("sample(s)",
"{paste(head(repeated_samples, 3), collapse = ', ')}, and",
"{.val {length(tail(repeated_samples, -3))}} more samples.")
} else {
"sample(s) {repeated_samples}."
}))
}
## validation: soft check gap in sample_column > 1 hr
if (any(diff(sample_vector) > 3600)) {
big_gap <- raw_data_prepared |>
dplyr::filter(
c(diff(get(names(sample_column))) > 3600, FALSE)
) |>
dplyr::pull(index)
cli::cli_warn(paste(
"{.arg sample_column} = {.val {names(sample_column)}} has a gap",
"greater than 60 minutes. Consider investigating at sample(s)",
"{big_gap}."))
}
}
## estimate sample rate
if ("sample_rate" %in% names(args)) {
## return custom input sample rate
sample_rate <- args$sample_rate
} else if (
any(apply(
raw_data_pre[1:1000, ], 1,
\(row) all("Export sample rate" %in% row)))
) {
## manually extract Oxysoft sample rate
oxysoft_sample_row <- which(apply(
raw_data_pre[1:1000, ], 1,
\(row) all("Export sample rate" %in% row)))
sample_rate <- as.numeric(raw_data_pre[oxysoft_sample_row, 2])
cli::cli_alert_info(paste(
"Estimated sample rate is {.val {sample_rate}} Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
} else if (exists("sample_vector")) {
## TODO sample_rate will be incorrect if `sample_column` is sample number
## samples per second
sample_rate <- head(diff(sample_vector), 100) |>
mean(na.rm = TRUE) |>
(\(.x) round(1/.x, 1))()
cli::cli_alert_info(paste(
"Estimated sample rate is {.val {sample_rate}} Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
} else {
sample_rate <- 1
cli::cli_alert_info(paste(
"No {.arg sample_column} provided. Sample rate set to 1 Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
}
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\1619.csv)"
nirs_columns = c("SmO2 Live", "SmO2 Averaged", "THb")
sample_column = "hh:mm:ss"
sample_column = c("time" = "hh:mm:ss")
event_column = NULL
## import from either excel or csv
## report error when file is open and cannot be opened by readxl
if (grepl("xls(x)?", tools::file_ext(file_path))) {
raw_data_pre <- tryCatch({
readxl::read_excel(
path = file_path, col_names = FALSE, col_types = "text",
n_max = 1000) |>
suppressMessages()
}, error = \(e) {
if (stringr::str_detect(e$message, "cannot be opened")) {
cli::cli_abort(paste(
"{e} \n",
"{.arg file_path} = {.file {file_path}}",
"cannot be opened, likely because the file is in use."
))
} else {stop(e)}
})
## detect row where nirs_columns exists, assuming this is common header
## row for dataframe
header_row <- which(apply(
raw_data_pre[1:1000, ], 1,
\(row) all(nirs_columns %in% row)))
} else if (grepl("csv", tools::file_ext(file_path))) {
all_lines <- readLines(file_path, warn = FALSE)
header_row <- which(
Reduce(`&`, lapply(nirs_columns, grepl, x = all_lines)))
raw_data_pre <- data.table::fread(
file_path, fill = Inf, blank.lines.skip = FALSE,
strip.white = FALSE
) |>
tibble::as_tibble() |>
## drops columns where all(is.na()) or all(.==0) values
dplyr::select(dplyr::where(\(.x) !all(is.na(.x) | .x == 0))) |>
print(n=110)
}
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\1619.csv)"
nirs_columns = c("SmO2 Live", "SmO2 Averaged", "THb")
sample_column = c("time" = "hh:mm:ss")
event_column = NULL
.keep_all = FALSE
## import from either excel or csv
## report error when file is open and cannot be opened by readxl
if (grepl("xls(x)?", tools::file_ext(file_path))) {
raw_data_pre <- tryCatch({
readxl::read_excel(
path = file_path, col_names = FALSE, col_types = "text",
n_max = 1000) |>
suppressMessages()
}, error = \(e) {
if (stringr::str_detect(e$message, "cannot be opened")) {
cli::cli_abort(paste(
"{e} \n",
"{.arg file_path} = {.file {file_path}}",
"cannot be opened, likely because the file is in use."
))
} else {stop(e)}
})
## detect row where nirs_columns exists, assuming this is common header
## row for dataframe
header_row <- which(apply(
raw_data_pre[1:1000, ], 1,
\(row) all(nirs_columns %in% row)))
} else if (grepl("csv", tools::file_ext(file_path))) {
all_lines <- readLines(file_path, warn = FALSE)
header_row <- which(
Reduce(`&`, lapply(nirs_columns, grepl, x = all_lines)))
raw_data_pre <- data.table::fread(
file_path, fill = Inf, blank.lines.skip = FALSE,
strip.white = FALSE
) |>
tibble::as_tibble() |>
## drops columns where all(is.na()) or all(.==0) values
dplyr::select(dplyr::where(\(.x) !all(is.na(.x) | .x == 0)))
}
## validation: nirs_columns must be detected to extract the proper
## dataframe
if (rlang::is_empty(header_row)) {
cli::cli_abort(paste(
"{.arg nirs_columns} = `{.val {nirs_columns}}` {?was/were}",
"not detected in the data."))
}
## return error if nirs_columns string is detected multiple times
if (length(header_row) > 1) {
cli::cli_abort(paste(
"{.arg nirs_columns} = `{.val {nirs_columns}}` {?was/were}",
"detected at multiple locations. Please ensure that the names",
"in {.arg nirs_columns} are uniquely identifiable."))
}
header_row
## import from either excel or csv
## re-read the data at the proper row to extract the dataframe
if (stringr::str_ends(file_path, ".xls|.xlsx")) {
raw_data_trimmed <- readxl::read_excel(
path = file_path, skip = header_row - 1,
guess_max = 50000, na = c("", "NA")
) |>
## drops columns where all NA or 0
dplyr::select(dplyr::where(\(.x) !all(is.na(.x) | .x == 0))) |>
## drops rows where all NA
dplyr::filter(
dplyr::if_any(dplyr::everything(), \(.x) !is.na(.x))
) |>
suppressMessages()
} else if (stringr::str_ends(file_path, ".csv")) {
raw_data_trimmed <- utils::read.csv(
file = file_path, skip = header_row - 1,
check.names = FALSE, na.strings = c("", "NA")
) |>
tibble::as_tibble(.name_repair = "unique") |>
## drops columns where all NA or 0
dplyr::select(dplyr::where(\(.x) !all(is.na(.x) | .x == 0))) |>
## drops rows where all NA
dplyr::filter(
dplyr::if_any(dplyr::everything(), \(.x) !is.na(.x))
) |>
suppressMessages()
}
stringr::str_ends(file_path, ".xls|.xlsx")
raw_data_trimmed
## rename nirs_columns
names(nirs_columns) <- if (!is.null(names(nirs_columns))) {
replace(names(nirs_columns),
names(nirs_columns) == "",
nirs_columns[names(nirs_columns) == ""])
} else {nirs_columns}
## rename sample_column
names(sample_column) <- if (!is.null(names(sample_column))) {
replace(names(sample_column),
names(sample_column) == "",
sample_column[names(sample_column) == ""])
} else {sample_column}
## rename event_column
names(event_column) <- if (!is.null(names(event_column))) {
replace(names(event_column),
names(event_column) == "",
event_column[names(event_column) == ""])
} else {event_column}
## validation: check that sample_column and event_column
if (!is.null(sample_column)) {
if (!sample_column %in% names(raw_data_trimmed)) {
cli::cli_abort(paste(
"{.arg sample_column} = `{.val {sample_column}}` not detected.",
"Column names are case sensitive and should match exactly."))
}}
if (!is.null(event_column)) {
if (!event_column %in% names(raw_data_trimmed)) {
cli::cli_abort(paste(
"{.arg event_column} = `{.val {event_column}}` not detected.",
"Column names are case sensitive and should match exactly."))
}}
raw_data_prepared <- raw_data_trimmed |>
## keep_all selects everything, else only manual columns
dplyr::select(
dplyr::any_of(c(
sample_column,
event_column,
nirs_columns)),
if (.keep_all) dplyr::everything()
) |>
## rename columns from manual input
dplyr::rename(
dplyr::any_of(c(
nirs_columns,
sample_column,
event_column))
) |>
## drops columns where all(is.na()) or all(.==0) values
dplyr::select(dplyr::where(\(.x) !all(is.na(.x) | .x == 0))) |>
dplyr::mutate(
## convert blank values to NA
dplyr::across(
dplyr::where(is.numeric),
\(.x) ifelse(.x %in% c(Inf, -Inf, NaN), NA_real_, .x)),
dplyr::across(
dplyr::where(is.character),
\(.x) ifelse(.x %in% c("", "NA"), NA_character_, .x)),
) |>
( \(df) {
## drops rows after the first row where all(is.na())
## c(..., 0) ensures the last row will be taken when no rows
## are all(is.na)
first_allna_row <- which(
diff(c(rowSums(is.na(df)) != ncol(df), 0)) != 0)[1]
dplyr::slice_head(df, n = first_allna_row)
})() |>
dplyr::mutate(
## convert sample column to unique numeric values in seconds
## https://github.com/fmmattioni/whippr/blob/master/R/read-data.R
## detects either character or dttm formats
## tested on Moxy, PerfPro, Oxysoft, VMPro x2
## TODO test on Train.Red, NNOXX, Graspor, Oxysoft csv, ...
dplyr::across(
dplyr::any_of(names(sample_column)) &
dplyr::where(is.character),
\(.x) as.POSIXct(.x, tryFormats = c(
"%Y-%m-%d %H:%M:%OS", "%Y/%m/%d %H:%M:%OS", "%H:%M:%OS"),
format = "%H:%M:%OS")),
## adds a sequential index column
dplyr::across(
dplyr::any_of(names(nirs_columns[1])),
\(.x) seq_along(.x),
.names = "index"),
) |>
dplyr::relocate(index)
## Soft check sample values if sample_column is present
if (!is.null(names(sample_column))) {
sample_vector <- as.numeric(raw_data_prepared[[names(sample_column)]])
## validation: soft check whether sample_column has non-sequential or
## repeating values
if (any(c(diff(sample_vector) <= 0, FALSE) | duplicated(sample_vector))) {
repeated_samples <- raw_data_prepared |>
dplyr::filter(
c(diff(get(names(sample_column))) <= 0, FALSE) |
duplicated(get(names(sample_column)))
) |>
dplyr::pull(index)
cli::cli_warn(paste(
"{.arg sample_column} = {.val {names(sample_column)}} has",
"non-sequential or repeating values. Consider investigating at",
if (length(repeated_samples) > 5) {
paste("sample(s)",
"{paste(head(repeated_samples, 3), collapse = ', ')}, and",
"{.val {length(tail(repeated_samples, -3))}} more samples.")
} else {
"sample(s) {repeated_samples}."
}))
}
## validation: soft check gap in sample_column > 1 hr
if (any(diff(sample_vector) > 3600)) {
big_gap <- raw_data_prepared |>
dplyr::filter(
c(diff(get(names(sample_column))) > 3600, FALSE)
) |>
dplyr::pull(index)
cli::cli_warn(paste(
"{.arg sample_column} = {.val {names(sample_column)}} has a gap",
"greater than 60 minutes. Consider investigating at sample(s)",
"{big_gap}."))
}
}
## estimate sample rate
if ("sample_rate" %in% names(args)) {
## return custom input sample rate
sample_rate <- args$sample_rate
} else if (
any(apply(
raw_data_pre[1:1000, ], 1,
\(row) all("Export sample rate" %in% row)))
) {
## manually extract Oxysoft sample rate
oxysoft_sample_row <- which(apply(
raw_data_pre[1:1000, ], 1,
\(row) all("Export sample rate" %in% row)))
sample_rate <- as.numeric(raw_data_pre[oxysoft_sample_row, 2])
cli::cli_alert_info(paste(
"Estimated sample rate is {.val {sample_rate}} Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
} else if (exists("sample_vector")) {
## TODO sample_rate will be incorrect if `sample_column` is sample number
## samples per second
sample_rate <- head(diff(sample_vector), 100) |>
mean(na.rm = TRUE) |>
(\(.x) round(1/.x, 1))()
cli::cli_alert_info(paste(
"Estimated sample rate is {.val {sample_rate}} Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
} else {
sample_rate <- 1
cli::cli_alert_info(paste(
"No {.arg sample_column} provided. Sample rate set to 1 Hz.",
"Overwrite this by re-running with {.arg sample_rate = X}"
))
}
# #
# # ## VMPro
# read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)",
#     nirs_columns = c("SmO2[%]", "SmO2 -  2[%]", "THb[THb]"),
#     sample_column = "Time[s]",
#     event_column = NULL)
# # #
#
## Train Red
mNIRS::read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MF-TR-2025-03-20.csv)",
nirs_columns = c("SmO2" = "SmO2 unfiltered",
"HHb" = "HHb unfiltered",
"O2Hb" = "O2HB unfiltered"),
sample_column = c("time" = "Timestamp (seconds passed)"),
event_column = c("lap" = "Lap/Event")
)
# #
# # ## VMPro
# read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)",
#     nirs_columns = c("SmO2[%]", "SmO2 -  2[%]", "THb[THb]"),
#     sample_column = "Time[s]",
#     event_column = NULL)
# # #
#
## Train Red
mNIRS::read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MF-TR-2025-03-20.csv)",
nirs_columns = c("SmO2" = "SmO2 unfiltered",
"HHb" = "HHb unfiltered",
"O2Hb" = "O2HB unfiltered"),
sample_column = c("time" = "Timestamp (seconds passed)"),
event_column = c("lap" = "Lap/Event"))
read_data(
file_path = r"(C:\OneDrive - UBC\Body Position Study\Raw Data\SRLB02-Oxysoft-2024-12-20.xlsx)",
nirs_columns = "HHb",
sample_column = "time",
event_column = "event")
#     .keep_all = TRUE)
#
# ## Moxy
# read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\1619.csv)",
#     nirs_columns = c("SmO2 Live", "SmO2 Averaged", "THb"),
#     sample_column = c("time" = "hh:mm:ss"),
#     event_column = NULL)
# #
# # ## PerfPro
read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\Treadmill-VO2max-PerfPro-2024-12-16.xlsx)",
nirs_columns = "smo2_left_VL",
sample_column = "Time",
event_column = NULL)
read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\1619.csv)",
nirs_columns = c("SmO2 Live", "SmO2 Averaged", "THb"),
sample_column = c("time" = "hh:mm:ss"),
event_column = NULL)
# mNIRS::read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\DataAverage-VMPro-2023-05-17.xlsx)",
#     nirs_columns = c("right_smo2" = "SmO2[%]",
#                      "left_smo2" = "SmO2 -  2[%]",
#                      "thb" = "THb[THb]"),
#     sample_column = c("time" = "Time[hh:mm:ss]"),
#     event_column = NULL,
#     .keep_all = TRUE)
# #
# # ## VMPro
read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)",
nirs_columns = c("right_smo2" = "SmO2[%]",
"left_smo2" = "SmO2 -  2[%]",
"thb" = "THb[THb]"),
sample_column = c("time" = "Time[hh:mm:ss]"),
event_column = NULL)
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)"
nirs_columns = c("right_smo2" = "SmO2[%]",
"left_smo2" = "SmO2 -  2[%]",
"thb" = "THb[THb]")
sample_column = c("time" = "Time[hh:mm:ss]")
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)"
nirs_columns = c("right_smo2" = "SmO2[%]",
"left_smo2" = "SmO2 -  2[%]",
"thb" = "THb[THb]")
sample_column = c("time" = "Time[hh:mm:ss]")
event_column = NULL
grepl("xls(x)?", tools::file_ext(file_path))
raw_data_pre <- tryCatch({
readxl::read_excel(
path = file_path, col_names = FALSE, col_types = "text",
n_max = 1000) |>
suppressMessages()
}, error = \(e) {
if (stringr::str_detect(e$message, "cannot be opened")) {
cli::cli_abort(paste(
"{e} \n",
"{.arg file_path} = {.file {file_path}}",
"cannot be opened, likely because the file is in use."
))
} else {stop(e)}
})
raw_data_pre
# mNIRS::read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\DataAverage-VMPro-2023-05-17.xlsx)",
#     nirs_columns = c("right_smo2" = "SmO2[%]",
#                      "left_smo2" = "SmO2 -  2[%]",
#                      "thb" = "THb[THb]"),
#     sample_column = c("time" = "Time[hh:mm:ss]"),
#     event_column = NULL,
#     .keep_all = TRUE)
# #
# # ## VMPro
read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)",
nirs_columns = c("right_smo2" = "SmO2[%]",
"left_smo2" = "SmO2 -  2[%]",
"thb" = "THb[THb]"),
sample_column = c("time" = "Time[s]"),
event_column = NULL)
# mNIRS::read_data(
#     file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\DataAverage-VMPro-2023-05-17.xlsx)",
#     nirs_columns = c("right_smo2" = "SmO2[%]",
#                      "left_smo2" = "SmO2 -  2[%]",
#                      "thb" = "THb[THb]"),
#     sample_column = c("time" = "Time[hh:mm:ss]"),
#     event_column = NULL,
#     .keep_all = TRUE)
# #
# # ## VMPro
mNIRS::read_data(
file_path = r"(C:\OneDrive - UBC\Group Projects\JAData\MoxyUnit-VMPro-2023-05-17.xlsx)",
nirs_columns = c("right_smo2" = "SmO2[%]",
"left_smo2" = "SmO2 -  2[%]",
"thb" = "THb[THb]"),
sample_column = c("time" = "Time[s]"),
event_column = NULL)
